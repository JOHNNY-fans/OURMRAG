{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0658a545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "hop_data=[]\n",
    "file_path = \"/root/autodl-fs/OURMRAG/data/distill_gpt/retrieval_fix_0captipn.jsonl\"\n",
    "out_file_path=\"/root/autodl-fs/OURMRAG/data/stage_2/retrieval_sft_0captipn.jsonl\"\n",
    "with open(file_path, 'r') as infile:\n",
    "    for line in infile:\n",
    "        item=json.loads(line.strip())\n",
    "        hop_data.append(item)\n",
    "len(hop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f8cc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_json_files(directory):\n",
    "    data_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                data_list.append(data)\n",
    "    return data_list\n",
    "# 用法示例\n",
    "directory_path = '/root/autodl-fs/IMAGE/images_info'\n",
    "all_image_info = read_all_json_files(directory_path)\n",
    "image2format = {}\n",
    "for item in all_image_info:\n",
    "    for key in item:\n",
    "        image2format[str(key)] = item[str(key)]['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9afef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2_456.JPG'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2format['2_456']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9530ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_json_files(directory):\n",
    "    data_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                data_list.append(data)\n",
    "    return data_list\n",
    "# 用法示例\n",
    "directory_path = '/root/autodl-fs/IMAGE/images_info'\n",
    "all_image_info = read_all_json_files(directory_path)\n",
    "image2format = {}\n",
    "for item in all_image_info:\n",
    "    for key in item:\n",
    "        image2format[str(key)] = item[key]['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef3b66be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 'WEB_331',\n",
       " 'dataset': 'WEB',\n",
       " 'type': 'train',\n",
       " 'question': '\"What are the different colors used for the outer circles on the curling playing field at the 2010 Winter Olympics and 2002 Winter Olympics?\"',\n",
       " 'answer': 'During the 2010 Winter Olympics, the outer circles on the curling field were green <PIC>, but in 2002 they were red <PIC>.',\n",
       " 'all_images_list': [30102909, 30114054, 30366117, 30189869],\n",
       " 'solution': '<think>\\nThe question asks about the different colors used for the outer circles on the curling playing field at specific Winter Olympics, specifically the 2010 and 2002 Games. My internal knowledge isn\\'t enough for confidently recalling this detail, and it seems quite specific to require verification for accuracy.\\n\\nAnalyzing the retrieval results, for the Text-to-Text and Text-to-Image retrieval strategies, both yielded documents that directly address the question:\\n- The 2002 Winter Olympics had curling playing fields with outer circles in striking red.\\n- The 2010 Winter Olympics had curling playing fields with outer circles predominantly adorned in green.\\n\\nBoth the textual descriptions and associated image captions confirm this information. The necessary documents were retrieved, addressing the asked question adequately regarding the colors used at both Olympic events.\\n\\nTherefore, based on the information retrieved and analyzed, the decision type should be set to \"reference_sufficient\". Since the retrieved documents provide a complete answer, no further search is necessary.\\n</think>\\n<answer>\\n```json\\n{\\n    \"type\": \"reference_sufficient\",\\n    \"tool_uses\": null\\n}\\n```\\n</answer>',\n",
       " 'search_type': 'reference_sufficient',\n",
       " 'tool_uses': None,\n",
       " 'ref_chunks': ['10682_1', '10683_1'],\n",
       " 'image_find_chunks': ['10683_1', '10682_1', '10821_1'],\n",
       " 'query_find_chunks': ['10683_1', '10682_1', '11264_1'],\n",
       " 'input': 'You are asked to optimize the retrieval strategy for a Multimodal Retrieval-Augmented Generation (MRAG) task. Specifically, given a question , you need to analyze the inputs comprehensively and retrieve relevant multimodal reference documents to effectively answer the question.\\n\\nYou will receive the following input information:\\n\\n- **Question**: \"What are the different colors used for the outer circles on the curling playing field at the 2010 Winter Olympics and 2002 Winter Olympics?\"\\n\\n- **Available Retrieval Tools**: [{\\'type\\': \\'function\\', \\'function\\': {\\'name\\': \\'find_similar_docs\\', \\'description\\': \\'This is a Text-to-Text retrieval system that retrieves multimodal reference documents by first identifying semantically relevant texts for a set of input queries. It uses a vector (embedding) index to perform semantic similarity retrieval. Specifically, for each query, the tool retrieves `n` reference txext documents (where `n` is defined by the `top_n` parameter). Then, all documents retrieved from all queries are merged, and the top `n` reference documents are selected. The merging rules are as follows: 1) If a document is retrieved by multiple queries, it is given higher priority and ranks higher; 2) If documents have the same priority, they are sorted by similarity score.The retrieval tool is built on a multimodal corpus, where each text document is pre-associated with its corresponding multimodal content (images, image captions). Therefore, when relevant texts are retrieved, their linked multimodal documents are also obtained automatically as references. \\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'query\\': {\\'type\\': \\'array\\', \\'items\\': {\\'type\\': \\'string\\'}, \\'description\\': \\'A list of input text queries, where each element is a string.\\'}, \\'doc_type\\': {\\'type\\': \\'string\\', \\'description\\': \"The type of documents to retrieve. Valid options are \\'arxiv\\',\\'recipe\\',\\'web\\',\\'wiki\\' or \\'wit\\'\", \\'enum\\': [\\'arxiv\\', \\'recipe\\', \\'web\\', \\'wiki\\', \\'wit\\']}, \\'top_n\\': {\\'type\\': \\'integer\\', \\'description\\': \\'The number of reference documents to retain after merging. Multiple retrievers share a common quota. When the sum of their top_n values exceeds the total quota, each retriever is allocated a portion of the quota proportionally based on its top_n value.Currently, the total quota is fixed at 6. \\', \\'default\\': 3}}, \\'required\\': [\\'query\\', \\'doc_type\\', \\'top_n\\']}}}, {\\'type\\': \\'function\\', \\'function\\': {\\'name\\': \\'find_similar_image_by_query\\', \\'description\\': \\'This is a Text-to-Image retrieval tool that retrieves multimodal reference documents by first identifying semantically relevant images for a set of input text queries. It uses a vector (embedding) index to perform semantic similarity retrieval. Specifically, for each query, the tool retrieves `n` reference images (where `n` is defined by the `top_n` parameter). Then, all images retrieved from all query are merged, and the top `n` reference images are selected. The merging rules are as follows: 1) If a document is retrieved by multiple images, it is given higher priority and ranks higher; 2) If documents have the same priority, they are sorted by similarity score.Each retrieved image is part of a multimodal document,once an image is selected, the tools identifies its source document and extracts the surrounding textual context to construct a multimodal reference document.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'query\\': {\\'type\\': \\'array\\', \\'items\\': {\\'type\\': \\'string\\'}, \\'description\\': \\'A list of input text queries, where each element is a string.\\'}, \\'doc_type\\': {\\'type\\': \\'string\\', \\'description\\': \"The type of documents to retrieve. Valid options are \\'arxiv\\',\\'recipe\\',\\'web\\',\\'wiki\\' or \\'wit\\'\", \\'enum\\': [\\'arxiv\\', \\'recipe\\', \\'web\\', \\'wiki\\', \\'wit\\']}, \\'top_n\\': {\\'type\\': \\'integer\\', \\'description\\': \\'The number of reference documents to retain after merging. Multiple retrievers share a common quota. When the sum of their top_n values exceeds the total quota, each retriever is allocated a portion of the quota proportionally based on its top_n value.Currently, the total quota is fixed at 6.\\', \\'default\\': 3}}, \\'required\\': [\\'images\\', \\'doc_type\\', \\'top_n\\']}}}]\\n\\n- **Multimodal reference documents retrieved by basic retrieval strategy.**\\n\\n### Basic Retrieval Strategy:\\n1. **Text-to-Text Retrieval**:\\n   - Query list: includes only the original question.\\n   - Tool: Text-to-Text retriever (`find_similar_docs`), retrieves 3 relevant documents (`top_n=3`) from specified document type and then obtains their associated multimodal reference documents.\\n\\n2. **Text-to-Image Retrieval**:\\n   - Query list:  includes only the original question.\\n   - Tool: Text-to-Image retriever (`find_similar_image_by_query`), retrieves 3 relevant images (`top_n=3`) from specified document type then obtains their associated multimodal reference documents.\\n\\n### Current Retrieval Results:\\n- **Multimodal documents retrieved by Text-to-Text retriever**: Reference Document [1]: The 2002 Winter Olympics, officially known as the XIX Olympic Winter Games and commonly referred to as Salt Lake 2002, took place from February 8 to February 24, 2002, in and around Salt Lake City, Utah. This winter multi-sport event was marked by its vibrant and distinctive settings, particularly in events such as curling. The curling playing field featured outer circles painted in striking red, providing a vivid contrast against the white ice. This detail contributed to the iconic and memorable atmosphere of the sport during the Salt Lake City Winter Olympics, as spectators gathered in venues adorned with Olympic branding to witness the competitions.<PIC>\\n  The illustration of the Reference Document [1] : Image [1]\\n\\nReference Document [2]: The 2010 Winter Olympics, officially known as the XXI Olympic Winter Games, were held in Vancouver, British Columbia, Canada, from February 12 to February 28. This winter multi-sport event highlighted various competitions, including curling, a sport that requires exceptional precision and strategy. The curling playing field at these Olympics featured outer circles predominantly adorned in green, setting the stage for matches such as the one between athletes from the Swiss and Danish teams. The event underscored the intense competitive spirit and skillful gameplay characteristic of the Olympics, contributing to the dynamic and engaging atmosphere of the Games.<PIC>\\n  The illustration of the Reference Document [2] : Image [2]\\n\\nReference Document [3]: The 2002 Olympic cauldron, unveiled on January 8, 2002, at the Rice–Eccles Stadium in Salt Lake City, stands as a remarkable symbol of the Winter Olympic Games held that year. Costing 2 million dollars, this cauldron features an innovative design primarily composed of glass panels, which enable it to glow with the flame\\'s light, creating a striking visual effect against the evening sky. Its geometric shape further enhances its modern aesthetic, embodying the spirit of innovation and excellence celebrated at the Olympics. Following the conclusion of the 2002 Winter Games, the cauldron was relocated to the permanent Salt Lake 2002 Olympic Cauldron Park, adjacent to the original Olympic Stadium, where it remains a testament to the grandeur and success of the event.<PIC>\\n  The illustration of the Reference Document [3] : Image [4]\\n\\n\\n- **Multimodal documents retrieved by Text-to-Image retriever**: Reference Document [1]: The 2002 Winter Olympics, officially known as the XIX Olympic Winter Games and commonly referred to as Salt Lake 2002, took place from February 8 to February 24, 2002, in and around Salt Lake City, Utah. This winter multi-sport event was marked by its vibrant and distinctive settings, particularly in events such as curling. The curling playing field featured outer circles painted in striking red, providing a vivid contrast against the white ice. This detail contributed to the iconic and memorable atmosphere of the sport during the Salt Lake City Winter Olympics, as spectators gathered in venues adorned with Olympic branding to witness the competitions.<PIC>\\n   The illustration of the Reference Document [1] : Image [1]\\n\\nReference Document [2]: The 2010 Winter Olympics, officially known as the XXI Olympic Winter Games, were held in Vancouver, British Columbia, Canada, from February 12 to February 28. This winter multi-sport event highlighted various competitions, including curling, a sport that requires exceptional precision and strategy. The curling playing field at these Olympics featured outer circles predominantly adorned in green, setting the stage for matches such as the one between athletes from the Swiss and Danish teams. The event underscored the intense competitive spirit and skillful gameplay characteristic of the Olympics, contributing to the dynamic and engaging atmosphere of the Games.<PIC>\\n   The illustration of the Reference Document [2] : Image [2]\\n\\nReference Document [3]: The 2014 Winter Olympics Men\\'s 1500m Award Ceremony celebrated the achievements of the top athletes in the men\\'s 1500 meter event at the Sochi Winter Games. The ceremony took place in an indoor arena adorned with colorful Olympic-themed decor, highlighting the pride and honor bestowed upon the medalists Zbigniew Brodka, Koen Verweij, and Denny Morrison. Despite the intimate setting marked by a modest number of spectators and several empty seats, the event captured the triumph and dedication of the athletes who achieved medal honors in this prestigious competition.<PIC>\\n   The illustration of the Reference Document [3] : Image [3]\\n\\n\\n\\nWe also provide detailed captions of the retrieved images to support your retrieval analysis:\\nImage [1] \\'s caption : The image depicts a curling match occurring during the Salt Lake 2002 Winter Olympics. Here’s a structured description from multiple dimensions:\\n\\n1. **Setting and Venue**:\\n   - The event is taking place in an indoor sporting arena equipped for curling, visibly marked by Olympic branding elements. The words \"Salt Lake 2002\" and Olympic rings are prominently displayed on the walls and the edge of the ice rink.\\n\\n2. **Participants**:\\n   - The athletes in the image are engaged in the curling match representing their respective countries: Canada (CAN) and Norway (NOR). \\n   - One curler dressed in dark colors, possibly from the Norwegian team, is actively taking a shot, utilizing a broom in one hand for guiding the stone.\\n   - Other team members and officials are positioned around the ice rink.\\n\\n3. **Audience and Environment**:\\n   - Spectators are visible in the stands, many equipped with cameras, indicating a well-attended and potentially significant match within the Olympics context.\\n   - Several people wearing uniforms or jackets are seated near the game area, presumably coaches, officials, or other delegations involved in the competition.\\n\\n4. **Scoreboard and Game Progress**:\\n   - The electronic scoreboard provides detailed scores of the curling match. Norway (NOR) appears to be leading, with cumulative scores visible for each round: 1020101 against Canada’s 0002120.\\n   - The numbers likely refer to individual end scores and future projections or cumulative results.\\n\\n5. **Game Equipment and Layout**:\\n   - Curling stones are placed across the ice, with several positioned within the central target rings (house). Different colored stones suggest they belong to different teams.\\n   - The ice is marked with distinct, circular targets, which are integral to scoring in curling.\\n   - Brooms and other curling paraphernalia are evident, crucial for strategy and technique within the sport.\\n\\n6. **Action and Dynamics**:\\n   - The photograph captures a moment of active gameplay, showing an athlete in the midst of delivery, which includes precision aiming and release of the stone.\\n   - Team members may be observing strategy or awaiting their turn, poised for interaction as the stone traverses the ice.\\n\\nThis image encapsulates the essence of curling as a strategic Olympic winter sport, featuring the competitive element between nations and the communal atmosphere surrounding the event.\\n\\nImage [2] \\'s caption : **Scene Overview**\\n- The image depicts an indoor sporting event focused on the game of curling, evident from the ice rink, curling stones, and the athletes involved in gameplay.\\n\\n**Participants**\\n- Several players are on the ice, identifiable by their team jerseys. Most notable are players from Team Switzerland and Team Denmark, as indicated by the markings on their clothing.\\n- One athlete from Switzerland is prominently marked with the name \"Schafer.\"\\n- Team Denmark\\'s members can be identified, with one player\\'s back facing the camera and the label \"DENMARK\" visible on the jacket.\\n- An official or coach appears to be kneeling next to the stones, actively participating in the strategy discussion.\\n\\n**Setting**\\n- This appears to be a professional or international curling competition, as indicated by the presence of Olympic rings and the word \"Vancouver\" on the rink, suggesting a connection to the Vancouver 2010 Winter Olympics.\\n- Several rows of curling sheets can be seen in the background, with activity on each, highlighting a multi-game event or tournament setting.\\n\\n**Action**\\n- Players are gathered around the house (target area) engaged in strategic discussion or analysis regarding the placement of curling stones.\\n- The presence of various curling stones suggests a moment of decision-making or planning for the next move.\\n\\n**Additional Observations**\\n- A television camera operator is present, hinting at the event being recorded or broadcasted.\\n- Other team members or officials are positioned along the edge of the rink, observing or waiting for their turn to get involved.\\n- The ice rink is flanked by barriers with advertising or event branding, typical for professional sporting events.\\n\\nImage [3] \\'s caption : The image displays a scene from a medal ceremony at an ice-skating rink, presumably during an event at the Winter Olympics held in Sochi, Russia in 2014. Here is a structured description from multiple dimensions:\\n\\n### Spatial Composition\\n- **Foreground:** The main focus is the medal podium where three individuals are standing in a ceremonious manner. Each individual is dressed in different colored sports attire suggesting their national affiliations.\\n- **Midground:** Behind the podium, there is a group of photographers capturing the moment. They add a dynamic element to the composition.\\n- **Background:** Rows of multicolored seats, primarily red and beige, with some spectators seated. The backdrop includes large Olympic banners and logos, enhancing the significance of the event.\\n\\n### Participants\\n- **Athletes:** Three athletes are on the podium, each presumably having won a medal during the Olympic competition. They appear to be celebrating their achievements.\\n- **Photographers:** Positioned slightly behind the podium, capturing the event through cameras, indicating media coverage of the prestigious event.\\n- **Spectators & Officials:** Scattered throughout the seating area and on the rink, with some officials facilitating the ceremony.\\n\\n### Activity\\n- **Ceremonial Aspect:** The participants on the podium are captured in a victorious pose, likely raising their hands in celebration after receiving their medals.\\n- **Photography & Media Coverage:** A group of photographers are documenting the event, emphasizing world media engagement.\\n- **Spectator & Official Presence:** Audience members observe the ceremony, showcasing an element of national and international support.\\n\\n### Environmental Context\\n- **Setting:** Indoor ice rink environment, evident from the ice surface in the foreground, characteristic of winter sports venues.\\n- **Event Branding:** Various Olympic symbols such as rings and banners align with Sochi 2014 branding. \\n\\n### Visual Elements\\n- **Colors:** The vibrant hues of the athletes’ uniforms against the cool, white surface of the ice create visual appeal. Major colors include red, orange, and dark tones.\\n- **Lighting:** Bright indoor lighting illuminates the entire rink, ensuring visibility of all elements.\\n- **Architecture:** Modern architectural design of the venue, spacious with clear sightlines to accommodate large audiences.\\n\\nThis integrated view of the image provides a comprehensive understanding across different dimensions: spatial composition, participants, activity, environmental context, and visual elements.\\n\\nImage [4] \\'s caption : Certainly! Here\\'s a structured description of the image from multiple dimensions:\\n\\n### 1. **Physical Description:**\\n- **Object:** The image depicts the Olympic cauldron as used at the 2002 Winter Olympics in Salt Lake City, Utah.\\n- **Structure:** It is a geometric structure primarily made of transparent glass or acrylic panels arranged in a triangular pyramid shape.\\n- **Color:** The panels have a bluish tint, reflecting the sky and light around it.\\n- **Light and Fire:** The structure contains a flame at the top, emitting an orange glow through the transparent panels, contrasting vividly against the sky.\\n\\n### 2. **Artistic/Design Elements:**\\n- **Geometric Design:** The cauldron features sharp angles and a symmetrical triangular design, which creates a modern and dynamic appearance.\\n- **Transparency:** The use of clear materials allows light to pass through, creating an interplay between shadow and illumination that enhances its visual appeal.\\n- **Contrast:** The bright, warm colors of the flame sharply contrast with the cooler tones of the structure and sky, drawing focus to the flame.\\n\\n### 3. **Cultural Symbolism:**\\n- **Olympic Spirit:** The flame is a universal symbol representing the Olympic spirit, conveying ideals of unity, peace, and sportsmanship.\\n- **Tradition and History:** Olympic cauldrons are an integral part of the Games\\' opening and closing ceremonies, symbolizing the continuity of the Olympic tradition dating back to ancient Greece.\\n\\n### 4. **Technical Aspects:**\\n- **Construction Material:** Likely made from durable materials suitable for outdoor display and exposure to high temperatures from the flame.\\n- **Support Structure:** The cauldron is supported by a robust framework that holds the panels in a precise arrangement, ensuring structural integrity.\\n- **Lighting:** Designed to optimize visibility of the flame during both daytime and nighttime.\\n\\n### 5. **Emotional and Aesthetic Impact:**\\n- **Inspiration:** The towering structure and the eternal flame evoke feelings of inspiration, passion, and resilience.\\n- **Beauty:** The elegant design and dramatic illumination create an aesthetically pleasing spectacle.\\n\\nOverall, the image captures the intersection of architecture, symbolism, and design, encapsulating the spirit and grandeur of the Olympic Games through its impressive and iconic representation of the Olympic cauldron.\\n\\n\\nPlease follow these analytical steps to optimize the retrieval strategy:\\n\\n### Analysis and Decision Steps:\\n\\n1. **First, attempt to answer the question directly using your internal knowledge.**\\n\\n   * If the question can be **reasonably and confidently answered** without any retrieval — for example, if it involves commonsense facts, general world knowledge, or widely known topics — you **must immediately choose** the decision type `\"no_search_needed\"` and **stop further analysis**.\\n   * Do **not proceed to Step 2 or beyond** if Step 1 results in a sufficient answer. Early exit is required.\\n   * Retrieval (textual or visual) should only be considered if you **cannot** answer with confidence, or if your answer would be **incomplete or unreliable**.\\n\\n2. **Only if Step 1 fails**, proceed to evaluate the retrieved multimodal documents:\\n\\n   * If the retrieved documents are sufficient to clearly answer the question, set the decision type to `\"reference_sufficient\"`.\\n\\n3. **If the retrieved documents are also insufficient**, then:\\n\\n   * Clearly explain what specific information is missing.\\n   * Set the decision type to `\"further_search_required\"` and design a revised retrieval strategy, which may include:\\n\\n     * Decomposing or rephrasing the question to target specific aspects.\\n     * Adjusting `top_n` to optimize document scope.\\n     * Choosing between or combining Text-to-Text and Text-to-Image retrieval based on the query type.\\n\\n4. Always aim for **efficiency and sufficiency**. If at any point a confident answer is available, **stop there** and finalize the decision.\\n\\n### Note:\\n- If you decide \"no_search_needed\" or \"reference_sufficient\", set the \"tool_uses\" field to \"null\".\\n\\nProvide your final response strictly in the following format:\\n\\nFirst, clearly present your detailed analytical thought process within `<think>` tags. Then, output your structured JSON within `<answer>` tags, ensuring the JSON is correctly parsable by `json.loads`:\\n\\n<think>\\n    Clearly describe your analytical thought process here...\\n</think>\\n<answer>\\n    ```json\\n    {\\n        \"type\": \"your_decision_type\",\\n        \"tool_uses\": [\\n            {\\n                \"recipient_name\": \"function_name\",\\n                \"parameters\": {\\n                    \"parameter1\": \"value1\",\\n                    \"parameter2\": \"value2\"\\n                }\\n            }\\n        ]\\n    }\\n    ```\\n</answer>\\n    '}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hop_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76c6d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2_229.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2format['2_229']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5392c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "prefix_general = \"/root/autodl-fs/IMAGE/images/\"\n",
    "cnt=0\n",
    "new_data=[]\n",
    "for data in hop_data:\n",
    "    try:\n",
    "        img_abs_path_prefix = prefix_general + data['dataset'].upper() + '/'\n",
    "        all_abs_list=[img_abs_path_prefix+image2format[str(img)] for img in data['all_images_list']]\n",
    "        data['all_images_path']=all_abs_list\n",
    "        data['messages']=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": data['input']\n",
    "                }\n",
    "            ]\n",
    "        new_data.append(data)\n",
    "    except:\n",
    "        print(data)\n",
    "        cnt+=1\n",
    "        continue\n",
    "    # print(data['question_id'])\n",
    "    \n",
    "print(cnt)\n",
    "with open(out_file_path, 'w', encoding='utf-8') as f:\n",
    "    for item in new_data:\n",
    "        f.write(json.dumps(item,ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29bed30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "data1=[]\n",
    "data2=[]\n",
    "file_path = \"/root/autodl-fs/OURMRAG/data/stage_2/retrieval_sft_nocaptipn.jsonl\"\n",
    "out_file_path1=\"/root/autodl-fs/OURMRAG/data/stage_2/retrieval_sft_nocaptipn.jsonl\"\n",
    "out_file_path2=\"/root/autodl-fs/OURMRAG/data/stage_2/retrieval_sft_th_answer.jsonl\"\n",
    "with open(file_path, 'r') as infile:\n",
    "    for line in infile:\n",
    "        item=json.loads(line.strip())\n",
    "        if \"answer is\" in item['solution']:\n",
    "            data2.append(data)\n",
    "        else:\n",
    "            data1.append(data)\n",
    "with open(out_file_path1, 'w', encoding='utf-8') as f:\n",
    "    for item in data1:\n",
    "        f.write(json.dumps(item,ensure_ascii=False) + \"\\n\")\n",
    "with open(out_file_path2, 'w', encoding='utf-8') as f:\n",
    "    for item in data2:\n",
    "        f.write(json.dumps(item,ensure_ascii=False) + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5050b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are asked to optimize the retrieval strategy for a Multimodal Retrieval-Augmented Generation (MRAG) task. Specifically, given a question , you need to analyze the inputs comprehensively and retrieve relevant multimodal reference documents to effectively answer the question.\n",
      "\n",
      "You will receive the following input information:\n",
      "\n",
      "- **Question**: What are the specific ingredients and their amounts needed to make 'Banana Bread Pancakes (gluten Free)' before processing in the food processor?\n",
      "\n",
      "- **Available Retrieval Tools**: [{'type': 'function', 'function': {'name': 'find_similar_docs', 'description': 'This is a Text-to-Text retrieval system that retrieves multimodal reference documents by first identifying semantically relevant texts for a set of input queries. It uses a vector (embedding) index to perform semantic similarity retrieval. Specifically, for each query, the tool retrieves `n` reference txext documents (where `n` is defined by the `top_n` parameter). Then, all documents retrieved from all queries are merged, and the top `n` reference documents are selected. The merging rules are as follows: 1) If a document is retrieved by multiple queries, it is given higher priority and ranks higher; 2) If documents have the same priority, they are sorted by similarity score.The retrieval tool is built on a multimodal corpus, where each text document is pre-associated with its corresponding multimodal content (images, image captions). Therefore, when relevant texts are retrieved, their linked multimodal documents are also obtained automatically as references. ', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of input text queries, where each element is a string.'}, 'doc_type': {'type': 'string', 'description': \"The type of documents to retrieve. Valid options are 'arxiv','recipe','web','wiki' or 'wit'\", 'enum': ['arxiv', 'recipe', 'web', 'wiki', 'wit']}, 'top_n': {'type': 'integer', 'description': 'The number of reference documents to retain after merging. Multiple retrievers share a common quota. When the sum of their top_n values exceeds the total quota, each retriever is allocated a portion of the quota proportionally based on its top_n value.Currently, the total quota is fixed at 6. ', 'default': 3}}, 'required': ['query', 'doc_type', 'top_n']}}}, {'type': 'function', 'function': {'name': 'find_similar_image_by_query', 'description': 'This is a Text-to-Image retrieval tool that retrieves multimodal reference documents by first identifying semantically relevant images for a set of input text queries. It uses a vector (embedding) index to perform semantic similarity retrieval. Specifically, for each query, the tool retrieves `n` reference images (where `n` is defined by the `top_n` parameter). Then, all images retrieved from all query are merged, and the top `n` reference images are selected. The merging rules are as follows: 1) If a document is retrieved by multiple images, it is given higher priority and ranks higher; 2) If documents have the same priority, they are sorted by similarity score.Each retrieved image is part of a multimodal document,once an image is selected, the tools identifies its source document and extracts the surrounding textual context to construct a multimodal reference document.', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of input text queries, where each element is a string.'}, 'doc_type': {'type': 'string', 'description': \"The type of documents to retrieve. Valid options are 'arxiv','recipe','web','wiki' or 'wit'\", 'enum': ['arxiv', 'recipe', 'web', 'wiki', 'wit']}, 'top_n': {'type': 'integer', 'description': 'The number of reference documents to retain after merging. Multiple retrievers share a common quota. When the sum of their top_n values exceeds the total quota, each retriever is allocated a portion of the quota proportionally based on its top_n value.Currently, the total quota is fixed at 6.', 'default': 3}}, 'required': ['images', 'doc_type', 'top_n']}}}]\n",
      "\n",
      "- **Multimodal reference documents retrieved by basic retrieval strategy.**\n",
      "\n",
      "### Basic Retrieval Strategy:\n",
      "1. **Text-to-Text Retrieval**:\n",
      "   - Query list: includes only the original question.\n",
      "   - Tool: Text-to-Text retriever (`find_similar_docs`), retrieves 3 relevant documents (`top_n=3`) from specified document type and then obtains their associated multimodal reference documents.\n",
      "\n",
      "2. **Text-to-Image Retrieval**:\n",
      "   - Query list:  includes only the original question.\n",
      "   - Tool: Text-to-Image retriever (`find_similar_image_by_query`), retrieves 3 relevant images (`top_n=3`) from specified document type then obtains their associated multimodal reference documents.\n",
      "\n",
      "### Current Retrieval Results:\n",
      "- **Multimodal documents retrieved by Text-to-Text retriever**: Reference Document [1]: Introduction: Banana Bread Pancakes (gluten Free). <PIC> These pancakes are easy, quick (ready in under 10 minutes), and taste just like banana bread! I love that they are fluffy and taste like regular pancakes, even though they are gluten free. You could leave out the chocolate chips and make these plain (or substitute blueberries)....but I think dark chocolate makes everything taste better :)Ingredients: 2 ripe bananas, cut into chunks (use medium sized bananas, or you can use 1.5 giant bananas) 3 eggs 2/3 cup certified gluten free rolled oats pinch of salt bittersweet chocolate chipsInstructions: 1. Preheat your electric griddle to 350 degrees F. 2. In your food processor, put the bananas, eggs, oats and salt. Process on high speed until completely smooth. Scrape down the sides of the bowl with a rubber spatula and mix again until there are no lumps. 3. Pour your batter into a bowl. Using a 1/4 cup measuring cup, scoop the batter onto your griddle. This will make perfectly round 4-5 inch pancakes. Sprinkle the pancakes with chocolate chips (or blueberries....). 4. Cook until bubbles form on the surface and begin to pop.Flip over and cook for another 60-90 seconds. 5. Serve immediately (I serve these plain because the chocolate chips make them sweet enough). These also freeze well...defrost them in the fridge overnight and reheat in the microwave. Makes 9 four inch pancakes. Notes: My 3 year old has two opinions of food...its either delicious and he will eat it, or \"NOT delicious\" and he spits it out (charming, I know). These pancakes happily fall into the former category! He ate his entire breakfast and asked for seconds. They are so quick and easy....the perfect way to use up ripe bananas! Sometimes I also throw in a handful of chopped walnuts :)\n",
      "  The illustration of the Reference Document [1] : Image [4]\n",
      "\n",
      "Reference Document [2]: Introduction: Gluten Free Flatbread for Sandwiches/Burgers. <PIC> I have been working on this recipe for a long time, but it never came out exactly as I hoped for. I tried once again (adding onions this time) and they were perfect! I love cheese burgers and wanted to come up with a gluten free bun I could make from scratch at the very last minute. I wasn't sure what to call these, because they are nothing like a traditional hamburger bun....but that was honestly what I created them for. These are delicious, quick (under 20 minutes!) and inexpensive! They would be perfect for a turkey or ham sandwich too (anything savory.....I would not use this for a sweet filling like peanut butter and jelly).Ingredients: 1 cup shredded mozzarella cheese (full fat) 1 egg 1 TB coconut flour 1.5 tsp sorghum flour 1.5 tsp millet flour 1/8 tsp baking soda 1 tsp dried minced onion Salt and Pepper (about 5 grinds of each)Instructions: Preheat oven to 400 degrees F. Mix all ingredients in a bowl until well combined. Using your fingers, divide the mixture into 4 equal parts and spread in flat circles (about 4 inches each) on a parchment paper lined baking sheet.Bake for about 13 minutes, until the flatbreads are golden (check often...they go from perfect to burned very quickly). Remove from the oven and cool on a cooling rack. Serve warm or at room temperature. Makes 4 rounds...enough for 2 large sandwiches or cheeseburgers.Notes: Its hard to describe what makes these so delicious...but I think its a combination of the flavor (from the onions) and the crisp texture (from the cheese). I served these with burgers, spinach, and blue cheese and they were a big hit! They have a nice solid consistency and hold up well to the thickest sandwich you can come up with. Even though there is no yeast in this bread (and they don't have to \"rise\"), it is filled with little tiny pockets of air. I love that you can make homemade bread for sandwiches in less than 20 minutes!\n",
      "  The illustration of the Reference Document [2] : Image [5]\n",
      "\n",
      "Reference Document [3]: Introduction: Healthy No-Bake Recipes- Snacks and Desserts | Ep. 1. <PIC> This collection of recipes is delicious, healthy, and easy to make. These are snacks and desserts (most are Paleo) which do not require an oven. Let's get started!(Here is my video version. Video Instructable) Step 1: Frappuccino Base. Ingredients:1 spoonful of vanilla ice cream1/4 cup of milk2 cubes of iceRequires a blenderIn a blender, add your ice cream.Pour in the milk.Add in the cubes of ice.Blend until you reach a creamy texture.Serve in cups, or freeze and serve in bowls. Step 2: Green Tea Frappuccino. Ingredients:Frappuccino base (from step 1)Green tea bagsMake green tea by stirring the tea bags in warm water.Stir green tea into frap base.Serve in cup, or freeze and serve in bowls. Step 3: Butter Bars. Ingredients:3 spoonfuls of peanut (or almond) butterHandful of large nuts or fruitHandful of small nuts or fruitRequires a pie plate.Spread the peanut butter into the bottom of the pie plate.Sprinkle the large nuts onto the butter.Sprinkle the smaller nuts onto the butter.Cool in the fridge for 1 hour.To serve, cut chunk out and place onto a plate. Step 4: Fruit Kebabs. Ingredients:Fruit or vegetables Topping (I used peanut butter)Requires skewersCut small, thin slices of fruit. Stick slices onto skewers. Spread topping onto slices. To store, place in a plastic bag in the fridge.\n",
      "  The illustration of the Reference Document [3] : Image [6]\n",
      "\n",
      "\n",
      "- **Multimodal documents retrieved by Text-to-Image retriever**: Reference Document [1]: Introduction: MAN BAIT- Whiskey Bacon Donuts. <PIC> We all know the way to a man's heart is through his stomach. If you want to successfully compete with steak & beer, then you need to bring out the big guns: donuts, bacon and whiskey!Ingredients:Donuts: donut recipe adapted from secretdonutrecipe.com 2 cups flour 1/2 cup warm mashed potato 1/2 tsp kosher salt 1/4 cup sugar 1 cup warm milk (not hot) pinch of sugar 5 tsp. yeast Canola Oil for frying + 2 tbsp 1 cup milk pinch of sugarCandied Bacon 1/2 cup golden brown sugar 1/2 to 1 tsp. Cayenne pepper 8-10 Bacon SlicesWhiskey Glaze inspired by Saveur magazine's Maple glaze- I left out the maple syrup & added whiskey To taste- 3-5 tbsp high quality whiskey 2 cups confectioners sugar 1/4 cup heavy cream pinch of kosher salt 5 tbsp. WhiskeyMake the Dough: To make the donuts, start by gathering all the ingredients. The donut recipe suggests baking the potato in the microwave, but I boiled mine. Either way will work. Clean and peel your potato.Make the Whiskey Glaze: Combine whiskey, confectioners sugar, heavy cream & salt in a bowl. Whisk until smooth. Glaze the donuts: Dip the donuts face down into the glaze and using a circular motion with your wrist, coat the donut. Top immediately with the candied bacon sprinkles. cheers!\n",
      "   The illustration of the Reference Document [1] : Image [1]\n",
      "\n",
      "Reference Document [2]: Introduction: Honey Lemon Granola. <PIC> This is a very delicious granola recipe! You can put it over yogurt or with fruit. Ingredients :-4 cups quick or old fashioned oats (360g)- 1/2 cup honey (168 g)- 1/4 cup lemon juice (60 ml)- 1/4 cup canola oil ( 60ml)Instructions:Preheat oven to 325*F. Measure out 1/4 cup lemon juice and 1/2 cup honey. Mix together with fork until thoroughly combined. - to a large bowl add oats. Add honey mixture and oil. Stir together completely. - pour into a pan and bake for 25-30 minutes or until slightly brown. Make sure to STIR every 10 MINUTES! \n",
      "   The illustration of the Reference Document [2] : Image [2]\n",
      "\n",
      "Reference Document [3]: Introduction: Cookie Butter. <PIC> I first discovered cookie butter last year at my local grocer Trader Joe's. Being a cookie lover, I was more than excited to grab a jar and get home as quickly as I could to try it. To my disappointment, it tasted like eating a gingerbread cookie. Not that I don't love gingerbread cookies! It just wasn't what I expected a \"Cookie Butter\" to taste like. The first cookie butter originated in Belgium and is made with the traditional & popular \"Speculoos\" aka Speculaas cookie. It's ingredients include cinnamon, clove, ginger, nutmeg, pepper, etc. Hence, the gingerbread flavor. Anywhoo, I wanted to create a \"Cookie Butter\" that didn't taste like \" Cookie Butter\". Does that make sense? So, I created this! The most delicious, rich and creamy homemade awesome goodness, that doesn't taste like a gingerbread cookie. Eat it with a spoon, put in on ice cream, eat it with fruit. There's no wrong way to eat cookie butter! Be creative! Cookie Butter has somewhat of a cult following and at some point there was a shortage. Imagine that! A \"cookie butter\" shortage.minutes or until the mixture is soft and creamy. Next, add the cookies. Blend until all the cookies are well combined. Last, add 1 tsp of vanilla extract and a pinch of salt. Give the butter one last pulse. Vilola! Cookie Butter! Store your Cookie Butter in an airtight Jar or container. I would recommend refrigeration, although it may firm up a bit. You can let it sit out at room temp for 30 minutes to allow the consistency to soften up a bit if you wish! \n",
      "   The illustration of the Reference Document [3] : Image [3]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### Analysis and Decision Steps:\n",
      "\n",
      "1. **First, attempt to answer the question directly using your internal knowledge.**\n",
      "\n",
      "   * If the question can be **reasonably and confidently answered** without any retrieval — for example, if it involves commonsense facts, general world knowledge, or widely known topics — you **must immediately choose** the decision type `\"no_search_needed\"` and **stop further analysis**.\n",
      "   * Do **not proceed to Step 2 or beyond** if Step 1 results in a sufficient answer. Early exit is required.\n",
      "   * Retrieval (textual or visual) should only be considered if you **cannot** answer with confidence, or if your answer would be **incomplete or unreliable**.\n",
      "\n",
      "2. **Only if Step 1 fails**, proceed to evaluate the retrieved multimodal documents:\n",
      "\n",
      "   * If the retrieved documents are sufficient to clearly answer the question, set the decision type to `\"reference_sufficient\"`.\n",
      "\n",
      "3. **If the retrieved documents are also insufficient**, then:\n",
      "\n",
      "   * Clearly explain what specific information is missing.\n",
      "   * Set the decision type to `\"further_search_required\"` and design a revised retrieval strategy, which may include:\n",
      "\n",
      "     * Decomposing or rephrasing the question to target specific aspects.\n",
      "     * Adjusting `top_n` to optimize document scope.\n",
      "     * Choosing between or combining Text-to-Text and Text-to-Image retrieval based on the query type.\n",
      "\n",
      "4. Always aim for **efficiency and sufficiency**. If at any point a confident answer is available, **stop there** and finalize the decision.\n",
      "\n",
      "### Note:\n",
      "- If you decide \"no_search_needed\" or \"reference_sufficient\", set the \"tool_uses\" field to \"null\".\n",
      "\n",
      "\n",
      "Provide your final response strictly in the following format:\n",
      "\n",
      "First, clearly present your detailed analytical thought process within `<think>` tags. Then, output your structured JSON within `<answer>` tags, ensuring the JSON is correctly parsable by `json.loads`:\n",
      "\n",
      "<think>\n",
      "    Clearly describe your analytical thought process here...\n",
      "</think>\n",
      "<answer>\n",
      "    ```json\n",
      "    {\n",
      "        \"type\": \"your_decision_type\",\n",
      "        \"tool_uses\": [\n",
      "            {\n",
      "                \"recipient_name\": \"function_name\",\n",
      "                \"parameters\": {\n",
      "                    \"parameter1\": \"value1\",\n",
      "                    \"parameter2\": \"value2\"\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "    ```\n",
      "</answer>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(item['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "408031a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "data1=[]\n",
    "data2=[]\n",
    "file_path = \"/root/autodl-fs/OURMRAG/data/stage_2/retrieval_sft_9captipn.jsonl\"\n",
    "out_file_path1=\"/root/autodl-fs/OURMRAG/data/stage_2/retrieval_sft_9captipn.jsonl\"\n",
    "out_file_path2=\"/root/autodl-fs/OURMRAG/data/stage_2/9retrieval_sft_th_answer.jsonl\"\n",
    "with open(file_path, 'r') as infile:\n",
    "    for line in infile:\n",
    "        item=json.loads(line.strip())\n",
    "        if \"answer is\" in item['solution']:\n",
    "            data2.append(data)\n",
    "        else:\n",
    "            data1.append(data)\n",
    "with open(out_file_path1, 'w', encoding='utf-8') as f:\n",
    "    for item in data1:\n",
    "        f.write(json.dumps(item,ensure_ascii=False) + \"\\n\")\n",
    "with open(out_file_path2, 'w', encoding='utf-8') as f:\n",
    "    for item in data2:\n",
    "        f.write(json.dumps(item,ensure_ascii=False) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
