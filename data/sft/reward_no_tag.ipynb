{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2cbfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ms-swift/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "model_name_or_path = '/root/autodl-tmp/BAAI/bge-m3'\n",
    "model = BGEM3FlagModel(model_name_or_path, use_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e14f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "import string\n",
    "\n",
    "bert_en_path='/root/autodl-tmp/google-bert/bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdff01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# æå‰åŠ è½½æ¨¡å‹å’Œ tokenizer\n",
    "bert_tokenizer_en = AutoTokenizer.from_pretrained(bert_en_path)\n",
    "bert_model_en = AutoModel.from_pretrained(bert_en_path).eval()\n",
    "\n",
    "def get_token_embeddings(sentence, model, tokenizer):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    hidden_states = outputs.last_hidden_state.squeeze(0)\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return hidden_states[1:1+len(tokens)], tokens  # å»é™¤ [CLS]\n",
    "\n",
    "def cosine_similarity_matrix(x, y):\n",
    "    x_norm = F.normalize(x, dim=1)\n",
    "    y_norm = F.normalize(y, dim=1)\n",
    "    return torch.mm(x_norm, y_norm.transpose(0, 1))\n",
    "\n",
    "def compute_bertscore(cand_emb, ref_emb):\n",
    "    sim_matrix = cosine_similarity_matrix(cand_emb, ref_emb)\n",
    "    precision = sim_matrix.max(dim=1)[0].mean()\n",
    "    recall = sim_matrix.max(dim=0)[0].mean()\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return precision.item(), recall.item(), f1.item()\n",
    "\n",
    "def bertscore(cand, ref, tokenizer,model):\n",
    "    cand_emb, _ = get_token_embeddings(cand, model, tokenizer)\n",
    "    ref_emb, _ = get_token_embeddings(ref, model, tokenizer)\n",
    "    return compute_bertscore(cand_emb, ref_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ad27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0\n",
      "0.5552507638931274 0.601777970790863 0.5775789022445679\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor.item() cannot be called on meta tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m orm \u001b[38;5;241m=\u001b[39m AnswerContentReward()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_case \u001b[38;5;129;01min\u001b[39;00m test_cases:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# test_caseæ˜¯ä¸€ä¸ªå°æ‰¹æ¬¡çš„ completionsï¼ˆæ¯”å¦‚4æ¡å°completionï¼‰\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43morm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mone_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m, in \u001b[0;36mAnswerContentReward.__call__\u001b[0;34m(self, completions, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     futures \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     60\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(calculate_reward, index, completion, solution_data): index\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index, completion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(completions)\n\u001b[1;32m     62\u001b[0m     }\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[0;32m---> 65\u001b[0m         index, score \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m         the_score[index] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m the_score\n",
      "File \u001b[0;32m~/miniconda3/envs/ms-swift/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/ms-swift/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ms-swift/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mAnswerContentReward.__call__.<locals>.calculate_reward\u001b[0;34m(index, completion, solution_data)\u001b[0m\n\u001b[1;32m     49\u001b[0m ref \u001b[38;5;241m=\u001b[39m solution_data\n\u001b[1;32m     50\u001b[0m hyp \u001b[38;5;241m=\u001b[39m answer_text\n\u001b[0;32m---> 51\u001b[0m P, R, F1\u001b[38;5;241m=\u001b[39m\u001b[43mbertscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert_tokenizer_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbert_model_en\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(P, R, F1)\n\u001b[1;32m     53\u001b[0m reword\u001b[38;5;241m=\u001b[39m(rouge_l\u001b[38;5;241m+\u001b[39mcos_sim\u001b[38;5;241m+\u001b[39mP\u001b[38;5;241m+\u001b[39mR\u001b[38;5;241m+\u001b[39mF1)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m     \n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mbertscore\u001b[0;34m(cand, ref, tokenizer, model)\u001b[0m\n\u001b[1;32m     30\u001b[0m cand_emb, _ \u001b[38;5;241m=\u001b[39m get_token_embeddings(cand, model, tokenizer)\n\u001b[1;32m     31\u001b[0m ref_emb, _ \u001b[38;5;241m=\u001b[39m get_token_embeddings(ref, model, tokenizer)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute_bertscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_emb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m, in \u001b[0;36mcompute_bertscore\u001b[0;34m(cand_emb, ref_emb)\u001b[0m\n\u001b[1;32m     25\u001b[0m recall \u001b[38;5;241m=\u001b[39m sim_matrix\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     26\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m precision \u001b[38;5;241m*\u001b[39m recall \u001b[38;5;241m/\u001b[39m (precision \u001b[38;5;241m+\u001b[39m recall \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprecision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, recall\u001b[38;5;241m.\u001b[39mitem(), f1\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/ms-swift/lib/python3.10/site-packages/torch/_meta_registrations.py:6471\u001b[0m, in \u001b[0;36mmeta_local_scalar_dense\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6469\u001b[0m \u001b[38;5;129m@register_meta\u001b[39m(aten\u001b[38;5;241m.\u001b[39m_local_scalar_dense)\n\u001b[1;32m   6470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmeta_local_scalar_dense\u001b[39m(\u001b[38;5;28mself\u001b[39m: Tensor):\n\u001b[0;32m-> 6471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.item() cannot be called on meta tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor.item() cannot be called on meta tensors"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class AnswerContentReward():\n",
    "    def __call__(self, completions: List[str], **kwargs) -> List[float]:\n",
    "        \n",
    "        solution_data = kwargs['solution']\n",
    "        # print(dataset)\n",
    "        # print(lan)\n",
    "        # print(solution_data)\n",
    "        def cosine_similarity(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "            a_norm = torch.norm(a)\n",
    "            b_norm = torch.norm(b)\n",
    "            if a_norm.item() == 0 or b_norm.item() == 0:\n",
    "                return 0.0\n",
    "            return torch.dot(a, b).item() / (a_norm.item() * b_norm.item())\n",
    "        \n",
    "        def normalize_answer(s):\n",
    "            def white_space_fix(text):\n",
    "                return ' '.join(text.split())\n",
    "            def remove_punc(text):\n",
    "                exclude = set(string.punctuation)\n",
    "                return ''.join(ch for ch in text if ch not in exclude)\n",
    "            def lower(text):\n",
    "                return text.lower()\n",
    "            return white_space_fix(remove_punc(lower(s)))\n",
    "\n",
    "        def calculate_reward(index: int, completion: str, solution_data: str) -> (int, float):\n",
    "            # try:\n",
    "                # answer_match = re.search(r\"<answer>(.*?)</answer>\", completion, re.DOTALL)\n",
    "                # if not answer_match:\n",
    "                #     return index, 0.0\n",
    "                # answer_text = answer_match.group(1).strip()\n",
    "                answer_text=completion\n",
    "                completion_emb = model.encode(answer_text)['dense_vecs']\n",
    "                solution_emb = model.encode(solution_data)['dense_vecs']\n",
    "                # è½¬ä¸ºfloat32çš„tensor\n",
    "                completion_emb = torch.tensor(completion_emb, dtype=torch.float16)\n",
    "                solution_emb = torch.tensor(solution_emb, dtype=torch.float16)\n",
    "                cos_sim = cosine_similarity(completion_emb, solution_emb)\n",
    "                # print(cos_sim)\n",
    "                scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "                score = scorer.score(solution_data, answer_text)\n",
    "                rouge_l = score[\"rougeL\"].fmeasure\n",
    "                ref = solution_data\n",
    "                hyp = answer_text\n",
    "                P, R, F1=bertscore(hyp, ref, bert_tokenizer_en,bert_model_en)\n",
    "                print(P, R, F1)\n",
    "                reword=(rouge_l+cos_sim+P+R+F1)/5     \n",
    "                return index,reword\n",
    "            # except:    \n",
    "            #     return index, 0.0\n",
    "        the_score = [0.0] * len(completions)\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = {\n",
    "                executor.submit(calculate_reward, index, completion, solution_data): index\n",
    "                for index, completion in enumerate(completions)\n",
    "            }\n",
    "            for future in futures:\n",
    "                \n",
    "                index, score = future.result()\n",
    "                the_score[index] = score\n",
    "        return the_score\n",
    "    \n",
    "one_data = {\n",
    "    \"id\": \"harvard_test_001\",\n",
    "    \"dataset\": \"mramg\",\n",
    "    \"lan\": \"en\",\n",
    "    \"solution\": \"The patient underwent laser iridotomy in both eyes for glaucoma treatment.\",\n",
    "}\n",
    "test_cases = [\n",
    "    [   # Row 1 - ç»“æ„å®Œæ•´ï¼Œå„ç±»è¯„åˆ†ä¾‹å­\n",
    "        # ğŸ”µ é«˜åˆ†ï¼šå®Œå…¨è´´åˆ\n",
    "        \"<answer>The patient underwent laser iridotomy in both eyes for glaucoma treatment.</answer>\",\n",
    "        # ğŸŸ¡ ä¸­åˆ†ï¼šéƒ¨åˆ†ç›¸å…³\n",
    "        \"<answer>The patient had a treatment related to eyes, possibly involving surgery.</answer>\",\n",
    "        # ğŸ”´ ä½åˆ†ï¼šå®Œå…¨æ— å…³\n",
    "        \"<answer>I went to the park and saw ducks in the pond.</answer>\",\n",
    "        # âŒ é”™è¯¯æ ¼å¼ï¼šæ²¡æœ‰ answer æ ‡ç­¾\n",
    "        \"The patient underwent laser iridotomy in both eyes for glaucoma treatment.\",\n",
    "    ],\n",
    "    [   # Row 2 - ä¸­æ–‡ mramg æ•°æ®é›†\n",
    "        \"<answer>æ‚£è€…åŒçœ¼æ¥å—äº†æ¿€å…‰è™¹è†œåˆ‡å¼€æœ¯ï¼Œç”¨äºæ²»ç–—é’å…‰çœ¼ã€‚</answer>\",      \n",
    "        \"<answer>æ‚£è€…æ¥å—äº†æŸç§æ²»ç–—çœ¼ç›çš„æ‰‹æœ¯ã€‚</answer>\",                          \n",
    "        \"<answer>æˆ‘å–œæ¬¢åƒç«é”…å’Œæ‰“ç¯®çƒã€‚</answer>\",                                  \n",
    "        \"<answer>æ ‡ç­¾åµŒå¥—é”™è¯¯</answer>\",                             \n",
    "    ],\n",
    "]\n",
    "orm = AnswerContentReward()\n",
    "for test_case in test_cases:\n",
    "    # test_caseæ˜¯ä¸€ä¸ªå°æ‰¹æ¬¡çš„ completionsï¼ˆæ¯”å¦‚4æ¡å°completionï¼‰\n",
    "    result = orm(test_case,**one_data)\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-swift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
